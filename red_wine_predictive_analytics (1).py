# -*- coding: utf-8 -*-
"""Red Wine Predictive Analytics.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14cNF8OXBksFiqLCrpzwm_8BnJE0Q1o9f

# Persiapan Alat dan Bahan

## Import library
"""

import pandas as pd
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.neighbors import KNeighborsRegressor
from sklearn import metrics
from sklearn.metrics import precision_recall_fscore_support as score
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import AdaBoostRegressor
from sklearn.svm import SVC
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score

"""## Menyiapkan [Red Wine](https://www.kaggle.com/sh6147782/winequalityred) Dataset"""

df = pd.read_csv('/content/winequality-red.csv')
df.head()

"""# Data Exploratory

## Cek informasi pada dataset
"""

df.info()

## Informasi dalam bentuk statistik

df.describe()

"""*Terlihat bahwa nilai minimum dari 'citric acid' adalah 0, namun karena dataset ini berupa komposisi dari redwine maka saya asumsikan bahwa memang ada yang tidak mengandung 'citric acid'*

## Cek value apa yang terdapat pada kolom 'quality'
"""

df['quality'].value_counts()

"""*Terlihat bahwa ada 6 nilai pada kolom 'quality' dengan masing-masing jumlahnya, namun menurut saya nilai tersebut cukup membingungkan karena berupa angka, jadi akan saya ubah menjadi 'bad' dan 'good'*

## Melihat Korelasi antara label dan fitur yang lain
"""

plt.figure(figsize=(10, 8))
correlation_matrix = df.corr().round(2)
# annot = True to print the values inside the square
sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)

"""Terlihat bahwa korelasi antara label ('quality') dengan fitur yang lain ada yang cenderung memiliki korelasi positif dan ada juga yang cenderung memiliki korelasi negatif namun karena hanya sedikit yang memiliki korelasi lebih banyak terhadap label sehingga saya mengasumsikan bahwa fitur yang memiliki nilai korelasi pada interval 0 - 0.2 dan juga 0 - (-0.2) tidak terlalu berpengaruh terhadap label maka fitur tersebut yaitu *fixed acidity*, *residual sugar*, *chlorides*, *free sulfur dioxide*, *total sulfur dioxide*, *density* dan juga *pH* akan kita hapus

### Menghapus Fitur yang memiliki nilai korelasi sangat rendah
"""

df.drop(['fixed acidity', 'total sulfur dioxide', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'density', 'pH'], inplace=True, axis=1)

df

"""# Data Preparation

## Mengubah kolom quality

*disini saya berasumsi bahwa redwine dengan nilai quality kurang dari atau sama dengan 5 akan bernilai 'bad' dan nilai quality yang lebih dari 5 akan bernilai 'good'*

### Membuat fungsi untuk mengubah nilai pada kolom quality
"""

def quality(a):
    if a<=5:
        return "bad"
    elif a>5:
        return "good"

"""### Menambahkan fungsi untuk mengubah nilai pada kolom quality"""

df['quality'] = df['quality'].apply(quality)
df

"""## Melakukan Encoder pada kolom quality"""

encoder = LabelEncoder()
df['quality'] = encoder.fit_transform(df['quality'])

"""## Splitting data train dan test

### Menambahkan kolom fitur dan label ke dalam variabel
"""

X = df.drop('quality', axis=1)      #Fitur
y = df['quality']                   #Label

"""### Split data menjadi train dan test

disini saya membagi menjadi 80% data train dan 20% data test
"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)

print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)

"""## Normalisasi Data

### Scaling kolom fitur pada train data
"""

scaler = MinMaxScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

X_train

"""# Model Development

## K-Nearest Neighbours
"""

from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, y_train)
y_pred = knn.predict(X_test)

"""## Random Forest"""

RF = RandomForestClassifier(n_estimators=50, max_depth=16, random_state=32, n_jobs=-1)
RF.fit(X_train, y_train)
y_pred_rf = RF.predict(X_test)

"""## Support Vector Machine

"""

clf = SVC(kernel="rbf", probability=True)
clf.fit(X_train, y_train)
y_pred_svm = clf.predict(X_test)

"""# Evaluasi Model

## Perbandingan nilai precision, recall, f-score dari masing - masing model
"""

precision_knn, recall_knn, fscore_knn, support_knn = score(y_test,y_pred,average='macro')
precision_rf, recall_rf, fscore_rf, support_rf = score(y_test,y_pred_rf,average='macro')
precision_svm, recall_svm, fscore_svm, support_svm = score(y_test,y_pred_svm,average='macro')

models = pd.DataFrame(index=['precision', 'recall', 'f-score'],
                      columns=['KNN', 'RF', 'SVM'])
models.loc['precision', 'KNN'] = precision_knn
models.loc['precision', 'RF'] = precision_rf
models.loc['precision', 'SVM'] = precision_svm

models.loc['recall', 'KNN'] = recall_knn
models.loc['recall', 'RF'] = recall_rf
models.loc['recall', 'SVM'] = recall_svm

models.loc['f-score', 'KNN'] = fscore_knn
models.loc['f-score', 'RF'] = fscore_rf
models.loc['f-score', 'SVM'] = fscore_svm

models

fig, ax = plt.subplots()
models.plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

"""## Perbandingan nilai akurasi dari masing - masing model"""

acc_svm = accuracy_score(y_test,y_pred_svm)
acc_rf = accuracy_score(y_test,y_pred_rf)
acc_knn = accuracy_score(y_test,y_pred)

accuracy = pd.DataFrame(index=['Accuracy'],
                        columns=['KNN', 'RF', 'SVM'])
accuracy.loc['Accuracy', 'KNN'] = acc_knn
accuracy.loc['Accuracy', 'RF'] = acc_rf
accuracy.loc['Accuracy', 'SVM'] = acc_svm

accuracy

"""### Plotting nilai akurasi yang di dapatkan masing - masing model"""

fig, ax = plt.subplots()
accuracy.plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

"""*Terlihat bahwa model yang menggunakan algoritma Random Forest memiliki nilai akurasi yang lebih tinggi dibandingkan dengan KNN dan juga SVM dengan nilai akurasi 78% sedangkan KNN dan SVM masing - masing memiliki nilai akurasi 74% dan 75%. Jadi bisa diasumsikan bahwa model yang menggunakan Random Forest lebih baik dibandingkan dengan model yang lain*

## Melakukan pengujian model
"""

model_dict = {'KNN': knn, 'RF': RF, 'SVM': clf}

prediksi = X_test[:40:2].copy()
pred_dict = {'y_true':y_test[:40:2]}
for name, model in model_dict.items():
    pred_dict['prediksi_'+name] = model.predict(prediksi).round(1)
 
pd.DataFrame(pred_dict)

"""
Saat dilakukan pengujian menggunakan 20 test data, model yang menggunakan algoritma Random Forest mendapatkan lebih banyak prediksi benar dengan jumlah 19 dibandingkan model yang menggunakanalalgoritma KNN dan SVM dengan masing - masing jumlah benar adalah 16 prediksi yang benar"""

